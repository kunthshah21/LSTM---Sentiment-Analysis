{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319b1b9f",
   "metadata": {},
   "source": [
    "# Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503da4c6-8c0c-4ef8-bc96-016911392e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd85f33-807a-4506-9121-26c19e4fdd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset/tweet_emotions.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc9f09e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807a485",
   "metadata": {},
   "source": [
    "## Removing ID, duplicate and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2600622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   content    40000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#If there is any null value throughout the row, remove it.\n",
    "data = data.dropna()\n",
    "data = data.reset_index(drop=True)\n",
    "data.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef618d1c",
   "metadata": {},
   "source": [
    "It was noticed that there are no null values present, therefore no values were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb349a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the id column\n",
    "data = data.drop(['tweet_id'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10b1446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows before removing:  91\n",
      "Number of duplicate rows after removing:  0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplciate rows if they have the same \"content\" value. Also print the number of removed rows.\n",
    "print(\"Number of duplicate rows before removing: \", data.duplicated().sum())\n",
    "data = data.drop_duplicates(subset='content')\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"Number of duplicate rows after removing: \", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04f4dc",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb929bc7",
   "metadata": {},
   "source": [
    "The text cleaning function is designed to preprocess and clean the text data in the dataset. It performs the following operations:\n",
    "\n",
    "1. **Remove URLs**: Eliminates any URLs from the text.\n",
    "2. **Remove Non-Word Characters**: Replaces non-word characters with spaces.\n",
    "3. **Remove @Mentions**: Removes mentions (e.g., `@username`).\n",
    "4. **Remove Hashtags**: Removes the `#` symbol from hashtags.\n",
    "5. **Remove Non-ASCII Characters**: Removes any non-ASCII characters.\n",
    "6. **Remove Digits**: Eliminates digits from the text.\n",
    "7. **Fix Multiple Spaces**: Replaces multiple spaces with a single space.\n",
    "8. **Trim Spaces**: Removes leading and trailing spaces.\n",
    "\n",
    "The function is applied to the `content` column of the dataset to standardize the text format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab355556",
   "metadata": {},
   "source": [
    "### Text Cleaning Function Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fb3ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentiment                                            content\n",
      "0       empty  tiffanylue i know i was listenin to bad habit ...\n",
      "1     sadness  Layin n bed with a headache ughhhh waitin on y...\n",
      "2     sadness                     Funeral ceremony gloomy friday\n",
      "3  enthusiasm                wants to hang out with friends SOON\n",
      "4     neutral  dannycastillo We want to trade with someone wh...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    #remove any @mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    #remove # from #hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    #remove any non-ascii characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    #remove any digits\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    \n",
    "    \n",
    "    #Fix double or multiple spacing cause from removal\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    #Remove any leading or trailing spaces\n",
    "    text = re.sub(r'^\\s+|\\s+?$', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the \"content\" column\n",
    "data['content'] = data['content'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead12d56",
   "metadata": {},
   "source": [
    "Saving the cleaned data to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e689193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dataset/cleaned_tweet_emotions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eadeeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>tiffanylue i know i was listenin to bad habit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache ughhhh waitin on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo We want to trade with someone wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  tiffanylue i know i was listenin to bad habit ...\n",
       "1     sadness  Layin n bed with a headache ughhhh waitin on y...\n",
       "2     sadness                     Funeral ceremony gloomy friday\n",
       "3  enthusiasm                wants to hang out with friends SOON\n",
       "4     neutral  dannycastillo We want to trade with someone wh..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/cleaned_tweet_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324b571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39827, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "content      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5dddece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentiment                                            content  \\\n",
      "0       empty  tiffanylue i know i was listenin to bad habit ...   \n",
      "1     sadness  Layin n bed with a headache ughhhh waitin on y...   \n",
      "2     sadness                     Funeral ceremony gloomy friday   \n",
      "3  enthusiasm                wants to hang out with friends SOON   \n",
      "4     neutral  dannycastillo We want to trade with someone wh...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.009687531020362074, -0.11519767683321691, ...  \n",
      "1  [0.02141141140250999, -0.05418356123417788, -0...  \n",
      "2  [-0.042901569450643766, -0.05677819936404877, ...  \n",
      "3  [0.03292089124552941, 0.22727344006666284, 0.1...  \n",
      "4  [0.08450802176830757, 0.374923210176829, 0.003...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load Pre-trained GloVe Embeddings (200d)\n",
    "def load_glove_embeddings(filepath):\n",
    "    glove_dict = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_dict[word] = vector\n",
    "    return glove_dict\n",
    "\n",
    "# Convert tweets to TF-IDF weighted GloVe embeddings\n",
    "def get_tweet_embedding(tweet, glove_dict, tfidf, feature_names):\n",
    "    words = tweet.split()\n",
    "    tweet_vector = np.zeros(200)  # GloVe 200d\n",
    "    word_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        if word in glove_dict and word in feature_names:\n",
    "            weight = tfidf.get(word, 1)  # Default to 1 if word not in TF-IDF dict\n",
    "            tweet_vector += weight * glove_dict[word]\n",
    "            word_count += weight\n",
    "\n",
    "    return tweet_vector / word_count if word_count != 0 else tweet_vector\n",
    "\n",
    "# Load GloVe Embeddings\n",
    "glove_path = \"glove.twitter.27B.200d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_path)\n",
    "\n",
    "# TF-IDF Vectorizer (Fitted on Your Dataset)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_vectorizer.fit(df['content'])\n",
    "feature_names = set(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Get TF-IDF Scores\n",
    "idf_scores = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
    "\n",
    "# Convert Tweets to GloVe Embeddings\n",
    "df['embedding'] = df['content'].apply(lambda x: get_tweet_embedding(x, glove_embeddings, idf_scores, feature_names))\n",
    "\n",
    "# Check the output\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349330b",
   "metadata": {},
   "source": [
    "### Label encoding for the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4fe6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empty' 'sadness' 'enthusiasm' 'neutral' 'worry' 'surprise' 'love' 'fun'\n",
      " 'hate' 'happiness' 'boredom' 'relief' 'anger']\n"
     ]
    }
   ],
   "source": [
    "#print all unique values in the sentiment column\n",
    "print(df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b05a4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentiment                                            content  \\\n",
      "0       empty  tiffanylue i know i was listenin to bad habit ...   \n",
      "1     sadness  Layin n bed with a headache ughhhh waitin on y...   \n",
      "2     sadness                     Funeral ceremony gloomy friday   \n",
      "3  enthusiasm                wants to hang out with friends SOON   \n",
      "4     neutral  dannycastillo We want to trade with someone wh...   \n",
      "\n",
      "                                           embedding  sentiment_encoded  \n",
      "0  [-0.009687531020362074, -0.11519767683321691, ...                  0  \n",
      "1  [0.02141141140250999, -0.05418356123417788, -0...                  0  \n",
      "2  [-0.042901569450643766, -0.05677819936404877, ...                  0  \n",
      "3  [0.03292089124552941, 0.22727344006666284, 0.1...                  2  \n",
      "4  [0.08450802176830757, 0.374923210176829, 0.003...                  1  \n"
     ]
    }
   ],
   "source": [
    "#Perform label encoding in a new colomn. [empty, sadness, worry, hate, boredom, anger] is the first label which is negative. [neutral] label is neutral. [enthusiasm, love, fun, happiness, relief] is positive label. Create a new colomn for encoding.\n",
    "df['sentiment_encoded'] = df['sentiment'].apply(lambda x: 0 if x in ['empty', 'sadness', 'worry', 'hate', 'boredom', 'anger'] else 1 if x in ['neutral'] else 2)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c11212f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39826, 4)\n",
      "sentiment            object\n",
      "content              object\n",
      "embedding            object\n",
      "sentiment_encoded     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce8f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def parse_embedding(embedding):\n",
    "    # 1) If it's already a NumPy array, just ensure dtype float32.\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        return embedding.astype(np.float32)\n",
    "    \n",
    "    # 2) If it's a string that looks like \"array([-0.07, 0.08, ...])\", remove \"array(\" and trailing \")\".\n",
    "    if isinstance(embedding, str):\n",
    "        if embedding.startswith(\"array(\") and embedding.endswith(\")\"):\n",
    "            # remove the leading array( and trailing )\n",
    "            embedding = embedding[len(\"array(\"):-1]  # everything inside the parentheses\n",
    "\n",
    "        # now it should look like \"[-0.07, 0.08, ...]\"\n",
    "        python_list = ast.literal_eval(embedding)  # parse as Python list\n",
    "        return np.array(python_list, dtype=np.float32)\n",
    "    \n",
    "    # 3) Otherwise, try to convert it to float32 array anyway (covers lists or other formats).\n",
    "    return np.array(embedding, dtype=np.float32)\n",
    "\n",
    "# Now apply\n",
    "df['embedding'] = df['embedding'].apply(parse_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0804f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.68753081e-03 -1.15197673e-01  1.60114467e-03  6.72760904e-02\n",
      " -7.20403269e-02  1.47297859e-01  5.40728629e-01 -1.48637025e-02\n",
      " -3.08873057e-01 -3.68432611e-01  2.64210701e-02 -8.24295804e-02\n",
      " -6.73609018e-01 -1.20922513e-01  1.40795037e-02 -2.12514296e-01\n",
      "  1.42123729e-01  1.22511707e-01 -1.10287197e-01 -6.84935153e-02\n",
      "  8.92048776e-02  3.88010554e-02  3.59237716e-02 -2.04882324e-01\n",
      " -1.55432457e-02  1.09560859e+00 -9.63690355e-02  5.08775190e-02\n",
      " -1.70597211e-02 -1.00725733e-01 -8.15619975e-02 -6.00672141e-02\n",
      " -3.71983171e-01 -2.07319250e-03 -2.55327523e-01  1.18449517e-01\n",
      "  8.96067172e-03 -1.71255633e-01  1.96225077e-01  2.61133909e-02\n",
      "  5.39022923e-01  2.40764380e-01  1.49123102e-01 -6.02549203e-02\n",
      " -1.87833413e-01 -1.30441096e-02  4.63306576e-01 -1.86550915e-02\n",
      " -5.30624390e-02  9.78403836e-02  7.81050473e-02 -3.36621135e-01\n",
      " -8.14983472e-02 -1.78257227e-01 -3.73955537e-03  3.29251401e-02\n",
      " -6.43697083e-02 -1.70929253e-01  1.30399451e-01 -1.61359191e-01\n",
      "  1.14719747e-02  2.67389677e-02 -1.19935431e-01  3.94793674e-02\n",
      " -5.15856929e-02 -3.53798270e-02  1.00881524e-01  9.85632911e-02\n",
      "  5.82147874e-02 -1.52685300e-01 -2.83350199e-02  4.21459489e-02\n",
      " -8.49500373e-02 -6.58262447e-02  1.58309415e-01  1.17887981e-01\n",
      "  8.83121043e-02 -6.28392398e-02 -7.66730458e-02  1.08344190e-01\n",
      "  1.99433818e-01  9.66473669e-02 -1.73639670e-01  1.00991257e-01\n",
      "  3.00967526e-02  1.70533985e-01  3.36572416e-02 -2.72561640e-01\n",
      "  4.19109017e-02 -6.82864785e-02  1.27681851e-01  4.66218516e-02\n",
      " -7.25332424e-02 -7.50425011e-02  9.87646580e-02  1.77525520e-01\n",
      " -2.64060572e-02  9.52006355e-02  4.60944287e-02 -4.78212982e-02\n",
      " -4.13045995e-02 -3.36983353e-01 -1.42454989e-02  8.91385302e-02\n",
      " -7.30030313e-02  3.52402925e-02  1.51240930e-01 -7.03704059e-02\n",
      " -1.12952009e-01  6.43730015e-02 -9.86642987e-02 -1.49578735e-01\n",
      "  1.09156258e-01  1.37979403e-01 -2.89314896e-01 -3.15328725e-02\n",
      "  1.55490413e-01  1.22768529e-01 -2.71282662e-02  3.01488992e-02\n",
      "  4.66727540e-02 -2.26292565e-01  3.03591818e-01 -1.02513440e-01\n",
      " -8.91881585e-02  2.62759179e-01  2.74521094e-02 -6.83015734e-02\n",
      "  3.58034998e-01 -2.80684680e-02  1.39013166e-03  3.80318016e-02\n",
      " -3.53257135e-02 -3.79807279e-02 -2.26488203e-01 -1.62932038e-01\n",
      " -1.04998060e-01 -2.03526858e-02 -5.81698865e-02  1.26718298e-01\n",
      " -8.80449731e-03  2.38754943e-01 -3.61928320e-03 -8.39835405e-03\n",
      " -1.42190456e-01 -8.21552053e-03 -9.00906473e-02 -1.02291740e-01\n",
      "  1.93855584e-01 -1.37202755e-01  1.40560761e-01  9.98995602e-02\n",
      " -4.18441916e+00  5.54235205e-02 -1.28848910e-01 -1.96310524e-02\n",
      "  1.03285231e-01 -5.16464002e-02 -7.76793882e-02  2.09712284e-03\n",
      "  1.00940205e-01  9.96435340e-03  1.09414786e-01  2.98043303e-02\n",
      "  1.72680721e-01 -9.75225214e-03  2.57348567e-01  5.23938648e-02\n",
      " -4.96448539e-02 -1.82167292e-01  1.60996765e-02 -9.92796645e-02\n",
      " -7.40788803e-02 -1.07284784e-01 -5.38004227e-02 -2.49477476e-02\n",
      " -5.33737913e-02  8.63330141e-02 -9.69376713e-02  7.32706785e-02\n",
      " -1.01660885e-01  1.61736459e-01 -1.22601446e-02  6.81901798e-02\n",
      "  1.67497829e-01  1.07546292e-01  2.23612964e-01 -7.41570666e-02\n",
      "  8.92849118e-02 -7.45770661e-03 -6.89869374e-02 -1.76958203e-01\n",
      "  1.49697468e-01  1.20758384e-01 -5.73595986e-03 -4.65993360e-02\n",
      "  8.42112750e-02  4.01355743e-01 -1.63374469e-01 -8.53074118e-02]\n",
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(df['embedding'].iloc[0])\n",
    "print(type(df['embedding'].iloc[0]))  # <class 'numpy.ndarray'>\n",
    "print(df['embedding'].iloc[0].dtype)  # float32 (or float64, depending on your code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6bc5e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           embedding  sentiment_encoded\n",
      "0  [-0.009687531, -0.11519767, 0.0016011447, 0.06...                  0\n",
      "1  [0.021411411, -0.05418356, -0.049089134, -0.20...                  0\n",
      "2  [-0.042901568, -0.0567782, 0.06105573, 0.10129...                  0\n",
      "3  [0.03292089, 0.22727343, 0.10493607, -0.464905...                  2\n",
      "4  [0.084508024, 0.3749232, 0.0037533038, 0.09657...                  1\n"
     ]
    }
   ],
   "source": [
    "#Store only the embedding colomn and the sentiment_encoded colomn in a new dataframe.\n",
    "df = df[['embedding', 'sentiment_encoded']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576ecc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 27878\n",
      "Validation set size: 7965\n",
      "Test set size: 3983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temp dataset into validation (20% of original) and test (10% of original)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=1/3, random_state=42)\n",
    "\n",
    "# Print the sizes of the splits to verify\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90893a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.68753081e-03 -1.15197673e-01  1.60114467e-03  6.72760904e-02\n",
      " -7.20403269e-02  1.47297859e-01  5.40728629e-01 -1.48637025e-02\n",
      " -3.08873057e-01 -3.68432611e-01  2.64210701e-02 -8.24295804e-02\n",
      " -6.73609018e-01 -1.20922513e-01  1.40795037e-02 -2.12514296e-01\n",
      "  1.42123729e-01  1.22511707e-01 -1.10287197e-01 -6.84935153e-02\n",
      "  8.92048776e-02  3.88010554e-02  3.59237716e-02 -2.04882324e-01\n",
      " -1.55432457e-02  1.09560859e+00 -9.63690355e-02  5.08775190e-02\n",
      " -1.70597211e-02 -1.00725733e-01 -8.15619975e-02 -6.00672141e-02\n",
      " -3.71983171e-01 -2.07319250e-03 -2.55327523e-01  1.18449517e-01\n",
      "  8.96067172e-03 -1.71255633e-01  1.96225077e-01  2.61133909e-02\n",
      "  5.39022923e-01  2.40764380e-01  1.49123102e-01 -6.02549203e-02\n",
      " -1.87833413e-01 -1.30441096e-02  4.63306576e-01 -1.86550915e-02\n",
      " -5.30624390e-02  9.78403836e-02  7.81050473e-02 -3.36621135e-01\n",
      " -8.14983472e-02 -1.78257227e-01 -3.73955537e-03  3.29251401e-02\n",
      " -6.43697083e-02 -1.70929253e-01  1.30399451e-01 -1.61359191e-01\n",
      "  1.14719747e-02  2.67389677e-02 -1.19935431e-01  3.94793674e-02\n",
      " -5.15856929e-02 -3.53798270e-02  1.00881524e-01  9.85632911e-02\n",
      "  5.82147874e-02 -1.52685300e-01 -2.83350199e-02  4.21459489e-02\n",
      " -8.49500373e-02 -6.58262447e-02  1.58309415e-01  1.17887981e-01\n",
      "  8.83121043e-02 -6.28392398e-02 -7.66730458e-02  1.08344190e-01\n",
      "  1.99433818e-01  9.66473669e-02 -1.73639670e-01  1.00991257e-01\n",
      "  3.00967526e-02  1.70533985e-01  3.36572416e-02 -2.72561640e-01\n",
      "  4.19109017e-02 -6.82864785e-02  1.27681851e-01  4.66218516e-02\n",
      " -7.25332424e-02 -7.50425011e-02  9.87646580e-02  1.77525520e-01\n",
      " -2.64060572e-02  9.52006355e-02  4.60944287e-02 -4.78212982e-02\n",
      " -4.13045995e-02 -3.36983353e-01 -1.42454989e-02  8.91385302e-02\n",
      " -7.30030313e-02  3.52402925e-02  1.51240930e-01 -7.03704059e-02\n",
      " -1.12952009e-01  6.43730015e-02 -9.86642987e-02 -1.49578735e-01\n",
      "  1.09156258e-01  1.37979403e-01 -2.89314896e-01 -3.15328725e-02\n",
      "  1.55490413e-01  1.22768529e-01 -2.71282662e-02  3.01488992e-02\n",
      "  4.66727540e-02 -2.26292565e-01  3.03591818e-01 -1.02513440e-01\n",
      " -8.91881585e-02  2.62759179e-01  2.74521094e-02 -6.83015734e-02\n",
      "  3.58034998e-01 -2.80684680e-02  1.39013166e-03  3.80318016e-02\n",
      " -3.53257135e-02 -3.79807279e-02 -2.26488203e-01 -1.62932038e-01\n",
      " -1.04998060e-01 -2.03526858e-02 -5.81698865e-02  1.26718298e-01\n",
      " -8.80449731e-03  2.38754943e-01 -3.61928320e-03 -8.39835405e-03\n",
      " -1.42190456e-01 -8.21552053e-03 -9.00906473e-02 -1.02291740e-01\n",
      "  1.93855584e-01 -1.37202755e-01  1.40560761e-01  9.98995602e-02\n",
      " -4.18441916e+00  5.54235205e-02 -1.28848910e-01 -1.96310524e-02\n",
      "  1.03285231e-01 -5.16464002e-02 -7.76793882e-02  2.09712284e-03\n",
      "  1.00940205e-01  9.96435340e-03  1.09414786e-01  2.98043303e-02\n",
      "  1.72680721e-01 -9.75225214e-03  2.57348567e-01  5.23938648e-02\n",
      " -4.96448539e-02 -1.82167292e-01  1.60996765e-02 -9.92796645e-02\n",
      " -7.40788803e-02 -1.07284784e-01 -5.38004227e-02 -2.49477476e-02\n",
      " -5.33737913e-02  8.63330141e-02 -9.69376713e-02  7.32706785e-02\n",
      " -1.01660885e-01  1.61736459e-01 -1.22601446e-02  6.81901798e-02\n",
      "  1.67497829e-01  1.07546292e-01  2.23612964e-01 -7.41570666e-02\n",
      "  8.92849118e-02 -7.45770661e-03 -6.89869374e-02 -1.76958203e-01\n",
      "  1.49697468e-01  1.20758384e-01 -5.73595986e-03 -4.65993360e-02\n",
      "  8.42112750e-02  4.01355743e-01 -1.63374469e-01 -8.53074118e-02]\n",
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(df['embedding'].iloc[0])\n",
    "print(type(df['embedding'].iloc[0]))  # <class 'numpy.ndarray'>\n",
    "print(df['embedding'].iloc[0].dtype)  # float32 (or float64, depending on your code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d62fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (27878, 1, 200)\n",
      "y_train shape: (27878,)\n",
      "X_val shape: (7965, 1, 200)\n",
      "y_val shape: (7965,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_lstm_data(df, label_col='sentiment', embed_col='embedding'):\n",
    "    \"\"\"\n",
    "    df:       DataFrame with at least 2 columns: [label_col, embed_col]\n",
    "    label_col: name of the sentiment/label column\n",
    "    embed_col: name of the embedding column (a numerical vector or numeric data)\n",
    "    \"\"\"\n",
    "    # 1) Extract labels\n",
    "    y = df[label_col].values  # shape -> (num_samples,)\n",
    "\n",
    "    # 2) Extract numeric features (assuming 'embedding' column contains numeric vectors)\n",
    "    #    If 'embedding' is already stored as a vector (list/np.array) per row, convert each row to np.array:\n",
    "    X = np.array(df[embed_col].tolist())  # shape -> (num_samples, embedding_dim)\n",
    "\n",
    "    # 3) Reshape to 3D for LSTM: (samples, timesteps=1, features=embedding_dim)\n",
    "    #    If each row is just one “step” with that embedding:\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Example usage with train_df and val_df\n",
    "# -------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Keras / TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Sklearn for additional metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_train, y_train = prepare_lstm_data(train_df,\n",
    "                                     label_col='sentiment_encoded',\n",
    "                                     embed_col='embedding')\n",
    "\n",
    "X_val, y_val = prepare_lstm_data(val_df,\n",
    "                                 label_col='sentiment_encoded',\n",
    "                                 embed_col='embedding')\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  # (28000, 1, embedding_dim) for example\n",
    "print(\"y_train shape:\", y_train.shape)  # (28000,)\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01419c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # LSTM layer\n",
    "    model.add(LSTM(units=64, return_sequences=False, input_shape=input_shape))\n",
    "    # Optional Dropout\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer (binary classification -> 1 output neuron with sigmoid)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3badd07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m67,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,905</span> (265.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,905\u001b[0m (265.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,905</span> (265.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,905\u001b[0m (265.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: X_train.shape[1:] is (timesteps, features)\n",
    "model = build_lstm_model(X_train.shape[1:])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7221a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2410 - loss: -0.6799 - val_accuracy: 0.2939 - val_loss: -4.6501\n",
      "Epoch 2/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2864 - loss: -5.8441 - val_accuracy: 0.3140 - val_loss: -9.4798\n",
      "Epoch 3/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2976 - loss: -10.2061 - val_accuracy: 0.3254 - val_loss: -14.1459\n",
      "Epoch 4/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3031 - loss: -14.6552 - val_accuracy: 0.3041 - val_loss: -18.7950\n",
      "Epoch 5/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3015 - loss: -19.1884 - val_accuracy: 0.3053 - val_loss: -23.3421\n",
      "Epoch 6/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3011 - loss: -25.2534 - val_accuracy: 0.3358 - val_loss: -27.6855\n",
      "Epoch 7/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3131 - loss: -28.6115 - val_accuracy: 0.3086 - val_loss: -32.4672\n",
      "Epoch 8/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3079 - loss: -34.9267 - val_accuracy: 0.2996 - val_loss: -37.0356\n",
      "Epoch 9/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3079 - loss: -38.4604 - val_accuracy: 0.2984 - val_loss: -41.5599\n",
      "Epoch 10/10\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3102 - loss: -42.5412 - val_accuracy: 0.3343 - val_loss: -45.7502\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c265cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
